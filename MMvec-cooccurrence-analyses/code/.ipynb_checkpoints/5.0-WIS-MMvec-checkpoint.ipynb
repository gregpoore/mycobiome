{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from biom import (load_table,\n",
    "                  Table)\n",
    "from qiime2 import (Artifact,\n",
    "                    Metadata, Visualization)\n",
    "from qiime2.plugins.feature_table.actions import (rarefy)\n",
    "\n",
    "from qiime2.plugins.gemelli.actions import (rpca)\n",
    "from qiime2.plugins.mmvec.actions import (paired_omics,\n",
    "                                          summarize_paired)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skbio import OrdinationResults, DistanceMatrix\n",
    "from skbio.stats.distance import permanova\n",
    "from skbio.stats.composition import closure\n",
    "\n",
    "# plotting\n",
    "import colorsys\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mc\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "plt.style.use('seaborn') \n",
    "%matplotlib inline\n",
    "\n",
    "def match_all_table_subset(bt1, bt2, bt3, mf, \n",
    "                           use_catagory_col,\n",
    "                           use_catagory_subset,\n",
    "                           filter_for_strat = None,\n",
    "                           min_sample_count = 100,\n",
    "                           min_feature_count = 2,\n",
    "                           min_feature_samples = 10):\n",
    "    \n",
    "    # subset\n",
    "    mf_subset = mf.copy()[mf[use_catagory_col] == use_catagory_subset]\n",
    "\n",
    "    # copy and filter\n",
    "    bt1_subset = bt1.copy()\n",
    "    bt2_subset = bt2.copy()\n",
    "    bt3_subset = bt3.copy()\n",
    "    shared_ids = set(mf_subset.index) & set(bt1_subset.ids()) & set(bt2_subset.ids())  & set(bt3_subset.ids())\n",
    "    bt1_subset = bt1_subset.filter(shared_ids)\n",
    "    bt2_subset = bt2_subset.filter(shared_ids)\n",
    "    bt3_subset = bt3_subset.filter(shared_ids)\n",
    "    mf_subset = mf_subset.loc[shared_ids, :]\n",
    "    \n",
    "    # filter sample to min seq. depth\n",
    "    def sample_filter(val, id_, md):\n",
    "        return sum(val) > min_sample_count\n",
    "    # filter features to min total counts\n",
    "    def observation_filter(val, id_, md):\n",
    "        return sum(val) > min_feature_count\n",
    "    # filter features by N samples presence\n",
    "    def frequency_filter(val, id_, md):\n",
    "        return np.sum(val > 0) > min_feature_samples\n",
    "    \n",
    "    # filter bt1\n",
    "    n_features, n_samples = bt1_subset.shape\n",
    "    bt1_subset = bt1_subset.filter(observation_filter, axis='observation')\n",
    "    bt1_subset = bt1_subset.filter(frequency_filter, axis='observation')\n",
    "    bt1_subset = bt1_subset.filter(sample_filter, axis='sample')\n",
    "    # filter bt2\n",
    "    n_features, n_samples = bt2_subset.shape\n",
    "    bt2_subset = bt2_subset.filter(observation_filter, axis='observation')\n",
    "    bt2_subset = bt2_subset.filter(frequency_filter, axis='observation')\n",
    "    bt2_subset = bt2_subset.filter(sample_filter, axis='sample')\n",
    "    # filt bt3\n",
    "    bt3_subset = bt3_subset.filter(frequency_filter, axis='observation')\n",
    "    bt3_subset = Table(closure(bt3_subset.matrix_data.toarray().T).T,\n",
    "                       bt3_subset.ids('observation'),\n",
    "                       bt3_subset.ids())\n",
    "\n",
    "    \n",
    "    # double check all shared\n",
    "    shared_ids = set(mf_subset.index) & set(bt1_subset.ids()) & set(bt2_subset.ids())  & set(bt3_subset.ids())\n",
    "    mf_subset = mf_subset.loc[shared_ids, :]\n",
    "    if filter_for_strat is not None:\n",
    "        use_catagory_col2_counts = mf_subset[filter_for_strat].value_counts()\n",
    "        use_catagory_col2_counts = use_catagory_col2_counts[use_catagory_col2_counts > len(use_catagory_col2_counts)].index\n",
    "        mf_subset = mf_subset[mf_subset[filter_for_strat].isin(use_catagory_col2_counts)]\n",
    "       \n",
    "    shared_ids = set(mf_subset.index) & set(bt1_subset.ids()) & set(bt2_subset.ids())\n",
    "    bt1_subset = bt1_subset.filter(shared_ids)\n",
    "    bt2_subset = bt2_subset.filter(shared_ids)\n",
    "    bt3_subset = bt3_subset.filter(shared_ids)\n",
    "    mf_subset = mf_subset.loc[shared_ids, :]\n",
    "    # close the data - easier to generalize the mmvec params.\n",
    "    bt3_subset = Table(closure(bt3_subset.matrix_data.toarray().T).T,\n",
    "                       bt3_subset.ids('observation'),\n",
    "                       bt3_subset.ids())\n",
    "    bt2_subset = Table(closure(bt2_subset.matrix_data.toarray().T).T,\n",
    "                       bt2_subset.ids('observation'),\n",
    "                       bt2_subset.ids())\n",
    "    bt1_subset = Table(closure(bt1_subset.matrix_data.toarray().T).T,\n",
    "                       bt1_subset.ids('observation'),\n",
    "                       bt1_subset.ids())\n",
    "\n",
    "    \n",
    "    return bt1_subset, bt2_subset, bt3_subset, mf_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173, 513)\n",
      "(366, 513)\n",
      "(513, 11)\n"
     ]
    }
   ],
   "source": [
    "# import tables\n",
    "fungi_table = pd.read_csv('../data/WIS_fungi_and_bacteria_genus_data_all_samples/fungi_count_data_genus_all_summarized_WIS.csv', index_col=0).T\n",
    "bacterial_table = pd.read_csv('../data/WIS_fungi_and_bacteria_genus_data_all_samples/bacteria_count_data_genus_all_summarized_WIS.csv', index_col=0).T\n",
    "taxonomy = pd.read_csv('../data/WIS_fungi_and_bacteria_genus_data_all_samples/taxa_table_for_fungi_and_bacteria_genus_all_summarized_WIS.csv', index_col=0)\n",
    "fungi_taxonomy = taxonomy[taxonomy.kingdom == 'Fungi']\n",
    "bacterial_taxonomy = taxonomy[taxonomy.kingdom != 'Fungi']\n",
    "metadata = pd.read_csv('../data/WIS_fungi_and_bacteria_genus_data_all_samples/metadata_for_fungi_and_bacteria_genus_all_summarized_WIS.csv', index_col=0)\n",
    "metadata = metadata[metadata['type.detail'] == 'tumor']\n",
    "# subtypes defined from TCGA\n",
    "fungal_subtypes = pd.read_csv('../results/tables/log_ratio_comparisons/fungal-subtypes.csv', index_col=0)\n",
    "bacterial_subtypes = pd.read_csv('../results/tables/log_ratio_comparisons/bacterial-subtypes.csv', index_col=0)\n",
    "# generate log-ratio sub type groups\n",
    "fungal_genus_groupings_lr = {subtype:list(set(genus_set.index) & set(fungi_taxonomy.genus))\n",
    "                             for subtype, genus_set in fungal_subtypes.groupby('subtypes')}\n",
    "bacterial_genus_groupings_lr = {subtype:list(set(genus_set.index) & set(bacterial_taxonomy.genus))\n",
    "                             for subtype, genus_set in bacterial_subtypes.groupby('subtypes')}\n",
    "# group sum genus\n",
    "fungi_table.index = fungi_taxonomy.loc[fungi_table.index, 'genus']\n",
    "fungi_table = fungi_table.groupby(fungi_table.index).sum().drop(['other'])\n",
    "bacterial_table.index = bacterial_taxonomy.loc[bacterial_table.index, 'genus']\n",
    "bacterial_table = bacterial_table.groupby(bacterial_table.index).sum()\n",
    "# match the tables\n",
    "fungi_table = fungi_table.loc[fungi_table.sum(1) > 0, fungi_table.sum(0) > 0]\n",
    "bacterial_table = bacterial_table.loc[bacterial_table.sum(1) > 0, bacterial_table.sum(0) > 0]\n",
    "shared_ids = set(fungi_table.columns) & set(bacterial_table.columns) & set(metadata.index)\n",
    "metadata = metadata.reindex(shared_ids)\n",
    "fungi_table = fungi_table.reindex(shared_ids, axis=1)\n",
    "bacterial_table = bacterial_table.reindex(shared_ids, axis=1)\n",
    "fungi_table = fungi_table.loc[fungi_table.sum(1) > 0, fungi_table.sum(0) > 0]\n",
    "bacterial_table = bacterial_table.loc[bacterial_table.sum(1) > 0, bacterial_table.sum(0) > 0]\n",
    "fungi_bt = Table(fungi_table.values, fungi_table.index, fungi_table.columns)\n",
    "bacterial_bt = Table(bacterial_table.values, bacterial_table.index, bacterial_table.columns)\n",
    "\n",
    "print(fungi_table.shape)\n",
    "print(bacterial_table.shape)\n",
    "print(metadata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train cols \n",
    "mftmp = metadata.copy()\n",
    "strat_cols = ['tissue', 'material', 'center']\n",
    "# strat. train/test\n",
    "train, test = train_test_split(mftmp, test_size=0.25, random_state=0, \n",
    "                               stratify=mftmp[strat_cols])\n",
    "mftmp.loc[:, 'traintest'] = 'Train'\n",
    "mftmp.loc[test.index, 'traintest'] = 'Test'\n",
    "mftmp.index.name = 'sampleid'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breast      181\n",
       "lung        117\n",
       "melanoma     60\n",
       "ovary        43\n",
       "bone         36\n",
       "gbm          31\n",
       "pancreas     29\n",
       "colon        16\n",
       "Name: tissue, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.tissue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tumor    513\n",
       "Name: type.detail, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['type.detail'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bacteria-fungi', 'all-centers')\n",
      "128\n",
      "1381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 21679/94954 [00:17<00:57, 1265.88it/s]"
     ]
    }
   ],
   "source": [
    "def retrieve_q2(model, baseline):\n",
    "\n",
    "    # this provides a pseudo-r2 commonly provided in the context\n",
    "    # of logistic / multinomail model (proposed by Cox & Snell)\n",
    "    # http://www3.stat.sinica.edu.tw/statistica/oldpdf/a16n39.pdf\n",
    "    end = min(10, len(model.index))\n",
    "    # trim only the last 10 numbers\n",
    "\n",
    "    # compute a q2 score, which is commonly used in\n",
    "    # partial least squares for cross validation\n",
    "    cv_model = model.dropna()\n",
    "    cv_baseline = baseline.dropna()\n",
    "\n",
    "    l0 = np.mean(cv_baseline['cross-validation'][-end:])\n",
    "    lm = np.mean(cv_model['cross-validation'][-end:])\n",
    "    q2 = 1 - lm / l0\n",
    "    \n",
    "    return [q2]\n",
    "\n",
    "mmvec_results_all = {}\n",
    "mmvec_q2_all = {}\n",
    "\n",
    "latent_dim = 3\n",
    "\n",
    "data_subsets = {}\n",
    "data_subsets['all-centers'] = (bacterial_bt, fungi_bt, mftmp)\n",
    "\n",
    "for subset_tmp, (bt1tmp, bt2tmp, mftmp) in data_subsets.items():\n",
    "\n",
    "    bt1tmp, bt2tmp, mftmp = data_subsets[subset_tmp]\n",
    "\n",
    "    # import data\n",
    "    metadata_tmp = Metadata(mftmp)\n",
    "    # bacteria\n",
    "    table_one_tmp = Artifact.import_data('FeatureTable[Frequency]', bt1tmp)\n",
    "    # fungi\n",
    "    table_two_tmp = Artifact.import_data('FeatureTable[Frequency]', bt2tmp)\n",
    "    # save subset\n",
    "    metadata_tmp.save('../results/data-subsets-genus/%s_metadata_WIS.qza' % subset_tmp.lower().replace(' ','_'))\n",
    "    table_one_tmp.save('../results/data-subsets-genus/%s_bacteria_table_WIS.qza' % subset_tmp.lower().replace(' ','_'))\n",
    "    table_two_tmp.save('../results/data-subsets-genus/%s_fungal_table_WIS.qza' % subset_tmp.lower().replace(' ','_'))\n",
    "\n",
    "    # perams\n",
    "    tables_order = {\n",
    "                    'bacteria-fungi':[table_one_tmp, table_two_tmp],\n",
    "                    'fungi-bacteria':[table_two_tmp, table_one_tmp],\n",
    "                   }\n",
    "\n",
    "    for mmvec_run_type, (tmptbl1, tmptbl2) in tables_order.items():\n",
    "\n",
    "        n_iterations = 1e8\n",
    "        #batch_size_use = 10\n",
    "        batch_size_use = int(0.25 * tmptbl1.view(Table).shape[1])\n",
    "        total_microbe_reads = tmptbl1.view(Table).sum()\n",
    "        epochs_use = max(1, int((n_iterations * batch_size_use) / total_microbe_reads))\n",
    "        print((mmvec_run_type, subset_tmp))\n",
    "        print(batch_size_use)\n",
    "        print(epochs_use)\n",
    "        # run MMvec\n",
    "        model_res = paired_omics(tmptbl1,\n",
    "                                 tmptbl2,\n",
    "                                 latent_dim=latent_dim, \n",
    "                                 min_feature_count=10,\n",
    "                                 epochs=epochs_use,\n",
    "                                 batch_size=batch_size_use,\n",
    "                                 metadata=metadata_tmp,\n",
    "                                 training_column='traintest',\n",
    "                                 summary_interval=1, \n",
    "                                 equalize_biplot=True)\n",
    "        null_res = paired_omics(tmptbl1,\n",
    "                                tmptbl2,\n",
    "                                 latent_dim=0,\n",
    "                                 min_feature_count=10,\n",
    "                                 epochs=epochs_use,\n",
    "                                 batch_size=batch_size_use,\n",
    "                                 metadata=metadata_tmp,\n",
    "                                 training_column='traintest',\n",
    "                                 summary_interval=1, \n",
    "                                 equalize_biplot=True)\n",
    "        #paired_model_stats = summarize_paired(model_res.model_stats, null_res.model_stats) \n",
    "        # save results\n",
    "        model_res.conditionals.save('../results/mmvec-results-genus/%s-%s-conditionals-WIS.qza' % \n",
    "                                    (mmvec_run_type, subset_tmp.replace(' ','')))\n",
    "        model_res.conditional_biplot.save('../results/mmvec-results-genus/%s-%s-conditional-biplot-WIS.qza' % \n",
    "                                          (mmvec_run_type, subset_tmp.replace(' ','')))\n",
    "        #paired_model_stats.visualization.save('../results/mmvec-results/%s-%s-paired-model-stats.qzv' % \n",
    "        #                                      (mmvec_run_type, subset_tmp.replace(' ','')))\n",
    "        mmvec_results_all[subset_tmp] = (model_res, null_res)\n",
    "        # save just q2\n",
    "        model_tmp = model_res.model_stats.view(Metadata).to_dataframe()\n",
    "        baseline_tmp = null_res.model_stats.view(Metadata).to_dataframe()\n",
    "        mmvec_q2_all[(mmvec_run_type, subset_tmp)] = retrieve_q2(model_tmp,\n",
    "                                                                 baseline_tmp)\n",
    "        print(mmvec_q2_all[(mmvec_run_type, subset_tmp)])\n",
    "        model_tmp_cv = model_tmp.dropna().rolling(2).mean().dropna().reset_index()\n",
    "        baseline_tmp_cv = baseline_tmp.dropna().rolling(2).mean().dropna().reset_index()\n",
    "        plt.plot(model_tmp_cv.dropna()['iteration'], model_tmp_cv.dropna()['cross-validation'], label='model', c='#377eb8', lw=2)\n",
    "        plt.plot(baseline_tmp_cv.dropna()['iteration'], baseline_tmp_cv.dropna()['cross-validation'], label='baseline', c='#e41a1c', lw=2)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(model_tmp['iteration'], np.log(model_tmp['loss']),\n",
    "                 label='model', c='#377eb8', lw=2)\n",
    "        plt.plot(baseline_tmp['iteration'], np.log(baseline_tmp['loss']),\n",
    "                 label='baseline', c='#e41a1c', lw=2)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qiime2-2019.7)",
   "language": "python",
   "name": "qiime2-2019.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
